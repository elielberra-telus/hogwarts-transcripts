{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e888941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c56382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d922ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw-data-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b731988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user's content only\n",
    "df = df[df[\"role\"] == \"user\"].copy()\n",
    "df[\"content\"] = (\n",
    "    df[\"content\"]\n",
    "      .astype(str)\n",
    "      .str.replace(\"\\r\\n\", \"\\n\", regex=False)   # normalize Windows newlines\n",
    "      .str.replace(\"\\r\", \"\\n\", regex=False)     # normalize old Mac newlines\n",
    "      .str.replace(\"\\n\", r\"\\n\", regex=False)    # make newline visible\n",
    "      .str.slice(0, 2000)                       # trim to max 2000 chars\n",
    ")\n",
    "\n",
    "# 2) parse + sort (oldest first within each conversation)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
    "# tiebreaker: user first, then assistant\n",
    "role_order = {\"user\": 0, \"assistant\": 1}\n",
    "df[\"_role_order\"] = df[\"role\"].map(role_order).fillna(9).astype(int)\n",
    "df = df.sort_values([\"conversation_id\", \"date\",\"_role_order\"], ascending=True)\n",
    "\n",
    "# Separator that is very easy for an LLM to parse\n",
    "SEP = \"\\n<USER_TURN>\\n\"\n",
    "\n",
    "# Aggregate per conversation_id\n",
    "out = (\n",
    "    df.groupby(\"conversation_id\", as_index=False)\n",
    "      .agg(\n",
    "          content=(\"content\", lambda s: SEP.join(s.tolist())),\n",
    "          assistant_id=(\"assistant_id\", \"first\"),   # same within a conversation in your data\n",
    "          user_count=(\"content\", \"size\")            # number of user rows\n",
    "      )\n",
    ")\n",
    "\n",
    "# Keep only requested columns (order matters)\n",
    "out = out[[\"conversation_id\", \"content\", \"user_count\"]]\n",
    "\n",
    "# Save\n",
    "out.to_csv(\"users-by-conversation.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae03d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_count\n",
      "1     3825\n",
      "2     2980\n",
      "3     1967\n",
      "4      996\n",
      "5      644\n",
      "6      365\n",
      "7      225\n",
      "8      155\n",
      "9       90\n",
      "10      51\n",
      "11      32\n",
      "12      24\n",
      "13      12\n",
      "14      10\n",
      "15       6\n",
      "16       5\n",
      "17       3\n",
      "18       2\n",
      "19       4\n",
      "21       1\n",
      "22       4\n",
      "23       5\n",
      "24       1\n",
      "25       4\n",
      "26       1\n",
      "28       1\n",
      "30       1\n",
      "31       1\n",
      "33       1\n",
      "35       2\n",
      "39       1\n",
      "40       1\n",
      "50       1\n",
      "52       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many conversations have N user messages\n",
    "counts = (\n",
    "    out[\"user_count\"]\n",
    "      .value_counts()\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3d3cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 11422\n",
      "Average questions asked: 2.73\n"
     ]
    }
   ],
   "source": [
    "# Total rows (total conversations)\n",
    "total_rows = len(out)\n",
    "print(\"Total rows:\", total_rows)\n",
    "\n",
    "# Average questions per conversation\n",
    "avg_questions = out[\"user_count\"].mean()\n",
    "print(\"Average questions asked:\", round(avg_questions, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/2vrhtd1x3_zfcsn7k38kxp6r0000gn/T/ipykernel_15441/1578844713.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\"full_conversation\": build_full_conversation(g)}))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1) keep only user + assistant\n",
    "df = df[df[\"role\"].isin([\"user\", \"assistant\"])].copy()\n",
    "\n",
    "# Trim user and assistant's content to avoid exceeding LLM context window\n",
    "max_user_chars = 2000\n",
    "max_assistant_chars = 500\n",
    "def trim_by_role(row: pd.Series) -> str:\n",
    "    text = \"\" if pd.isna(row[\"content\"]) else str(row[\"content\"])\n",
    "    limit = max_user_chars if row[\"role\"] == \"user\" else max_assistant_chars if row[\"role\"] == \"assistant\" else None\n",
    "    return text[:limit] if limit is not None else text\n",
    "df[\"content\"] = df.apply(trim_by_role, axis=1)\n",
    "\n",
    "# 2) parse + sort (oldest first within each conversation)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
    "# tiebreaker: user first, then assistant\n",
    "role_order = {\"user\": 0, \"assistant\": 1}\n",
    "df[\"_role_order\"] = df[\"role\"].map(role_order).fillna(9).astype(int)\n",
    "df = df.sort_values([\"conversation_id\", \"date\",\"_role_order\"], ascending=True)\n",
    "\n",
    "# 3) build a per-conversation \"full_conversation\" JSONL-style string (easy to parse)\n",
    "def build_full_conversation(group: pd.DataFrame) -> str:\n",
    "    msgs = [{\"role\": r, \"content\": c} for r, c in zip(group[\"role\"], group[\"content\"])]\n",
    "    # one JSON object per line (JSONL) is very LLM-friendly\n",
    "    return \"\\n\".join(json.dumps(m, ensure_ascii=False) for m in msgs)\n",
    "\n",
    "df_conversations = (\n",
    "    df.groupby(\"conversation_id\", as_index=False)\n",
    "      .apply(lambda g: pd.Series({\"full_conversation\": build_full_conversation(g)}))\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7da92f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"role\": \"user\", \"content\": \"matching offer  from Rogers\"}\n",
      "{\"role\": \"assistant\", \"content\": \"I'd be happy to help you find information about matching offers against Rogers! To give you the most relevant guidance, I need a bit more context:\\n\\n---\\n\\n### ðŸ¤” **Quick Questions:**\\n\\n1. **What service are we matching?** (Internet, TV, Phone, or a bundle?)\\n2. **Which province is the customer in?** (This affects available options)\\n3. **What's the Rogers offer details?** (Speed, price, services included?)\\n4. **Is this an existing TELUS customer or a prospect?**\\n5. **What's their main concern?** (Pric\"}\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "print(final_df.loc[1, \"full_conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac63137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019bcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
